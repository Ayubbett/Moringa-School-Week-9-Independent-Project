{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Moringa_School_Data_Science_Core_W9_Independent_Project_2021_12_AYUB_BETT_Python_Notebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPqHBwQdGm2wrVRF7rqkKMv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayubbett/Moringa-School-Week-9-Independent-Project/blob/main/Moringa_School_Data_Science_Core_W9_Independent_Project_2021_12_AYUB_BETT_Python_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SPAM DETECTION**"
      ],
      "metadata": {
        "id": "1y8ovbFhj_pm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Defining the Question**"
      ],
      "metadata": {
        "id": "4P7q0SN-j8j-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a) Specifying the Data Analytic Question**"
      ],
      "metadata": {
        "id": "2zWA-GNyloQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An email is categorised as being a spam or not depending on the the content it has. So in thi problem we are to categorise the classification of an email being spam or not depending on what it contains."
      ],
      "metadata": {
        "id": "TPA3nxA5ljKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b) Defining the Metric for Success**"
      ],
      "metadata": {
        "id": "w1Di6VBmmbxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to build a Naive Bayes classifier to detect spam emails from the others. We are going to put the threshold for having a reliable Email at an accuracy of between 75% and 95%. Above that we are going to consider it overfitting the data and below it we shall conclude it underfitting."
      ],
      "metadata": {
        "id": "UOyKWGGvmgE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c) Understanding the context**"
      ],
      "metadata": {
        "id": "vvEfZN5dnacd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d) Recording the Experimental Design**"
      ],
      "metadata": {
        "id": "fPNrDYEyne8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are the steps we are going to take to approach our modelling:\n",
        "\n",
        "*   Load the necessary libraries for visualisation and data manipulation.\n",
        "*   Load the datset and view its columns and rows.\n",
        "\n",
        "*   Clean the data by looking at the missing values, duplicated values and any anomalies within the data.\n",
        "*   Perform exploratory data analysis that is Univariate analysis and Bivariate analysis.\n",
        "\n",
        "*   Perform feature engineering to get the best features to use.\n",
        "*   Perform modelling using Naive Bayes Classifier.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i2BLLgXEnznU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**e) Data Relevance**"
      ],
      "metadata": {
        "id": "W6Ff5kDVowqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Reading the Data**"
      ],
      "metadata": {
        "id": "vTKuTspbo4x6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "DKdZzLaLhvX4",
        "outputId": "115da58f-b7d2-4af2-f8a1-680c29bcd5dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0.64</th>\n",
              "      <th>0.64.1</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.32</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.64.2</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "      <th>0.10</th>\n",
              "      <th>0.32.1</th>\n",
              "      <th>0.11</th>\n",
              "      <th>1.29</th>\n",
              "      <th>1.93</th>\n",
              "      <th>0.12</th>\n",
              "      <th>0.96</th>\n",
              "      <th>0.13</th>\n",
              "      <th>0.14</th>\n",
              "      <th>0.15</th>\n",
              "      <th>0.16</th>\n",
              "      <th>0.17</th>\n",
              "      <th>0.18</th>\n",
              "      <th>0.19</th>\n",
              "      <th>0.20</th>\n",
              "      <th>0.21</th>\n",
              "      <th>0.22</th>\n",
              "      <th>0.23</th>\n",
              "      <th>0.24</th>\n",
              "      <th>0.25</th>\n",
              "      <th>0.26</th>\n",
              "      <th>0.27</th>\n",
              "      <th>0.28</th>\n",
              "      <th>0.29</th>\n",
              "      <th>0.30</th>\n",
              "      <th>0.31</th>\n",
              "      <th>0.32.2</th>\n",
              "      <th>0.33</th>\n",
              "      <th>0.34</th>\n",
              "      <th>0.35</th>\n",
              "      <th>0.36</th>\n",
              "      <th>0.37</th>\n",
              "      <th>0.38</th>\n",
              "      <th>0.39</th>\n",
              "      <th>0.40</th>\n",
              "      <th>0.41</th>\n",
              "      <th>0.42</th>\n",
              "      <th>0.778</th>\n",
              "      <th>0.43</th>\n",
              "      <th>0.44</th>\n",
              "      <th>3.756</th>\n",
              "      <th>61</th>\n",
              "      <th>278</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0  0.64  0.64.1  0.1  0.32   0.2  ...  0.43   0.44  3.756   61   278  1\n",
              "0  0.21  0.28     0.5  0.0  0.14  0.28  ...  0.18  0.048  5.114  101  1028  1\n",
              "\n",
              "[1 rows x 58 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#Importing the required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#columns = [['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our', 'word_freq_over', 'word_freq_remove',\n",
        "#           'word_freq_internet', 'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will', 'word_freq_people',\n",
        "#           'word_freq_report', 'word_freq_addresses', 'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', \n",
        "#          'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp', 'word_freq_hpl', \n",
        "#           'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857', 'word_freq_data', \n",
        "#          'word_freq_415', 'word_freq_85', 'word_freq_technology', 'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct',\n",
        "#           'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re', 'word_freq_edu', 'word_freq_table',\n",
        "#           'word_freq_conference', 'char_freq_colon', 'char_freq_parenthesis', 'char_freq_square', 'char_freq_apost', 'char_freq_dollar', 'char_freq_hash', \n",
        "#         'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total']]                                                         \n",
        "\n",
        "\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data')\n",
        "df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'0':'word_freq_make', '0.64':'word_freq_address', '0.64.1':'word_freq_all', '0.1':'word_freq_3d','0.32':'word_freq_our', '0.2':'word_freq_over', '0.3':'word_freq_remove',\n",
        "           '0.4':'word_freq_internet', '0.5':'word_freq_order', '0.6':'word_freq_mail', '0.7':'word_freq_receive', '0.64.2':'word_freq_will', '0.8':'word_freq_people',\n",
        "           '0.9':'word_freq_report', '0.10':'word_freq_addresses', '0.32.1':'word_freq_free', '0.11':'word_freq_business', '1.29':'word_freq_email', '1.93':'word_freq_you', \n",
        "          '0.12':'word_freq_credit', '0.96':'word_freq_your', '0.13':'word_freq_font', '0.14':'word_freq_000', '0.15':'word_freq_money', '0.16':'word_freq_hp', '0.17':'word_freq_hpl', \n",
        "           '0.18':'word_freq_george', '0.19':'word_freq_650', '0.20':'word_freq_lab', '0.21':'word_freq_labs', '0.22':'word_freq_telnet', '0.23':'word_freq_857', '0.24':'word_freq_data', \n",
        "          '0.25':'word_freq_415', '0.26':'word_freq_85', '0.27':'word_freq_technology', '0.28':'word_freq_1999', '0.29':'word_freq_parts', '0.30':'word_freq_pm', '0.31':'word_freq_direct',\n",
        "           '0.32':'word_freq_cs', '0.33':'word_freq_meeting', '0.34':'word_freq_original', '0.35':'word_freq_project', '0.36':'word_freq_re', '0.37':'word_freq_edu', '0.38':'word_freq_table',\n",
        "           '0.39':'word_freq_conference', '0.40':'char_freq_colon', '0.41':'char_freq_parenthesis', '0.42':'char_freq_square', '0.778':'char_freq_apost', '0.43':'char_freq_dollar', '0.44':'char_freq_hash', \n",
        "         '3.756':'capital_run_length_average', '61':'capital_run_length_longest', '278':'capital_run_length_total', '1':'Spam'}, inplace=True)"
      ],
      "metadata": {
        "id": "gyAqtfypE7CU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "iRNCEFPtJSQ1",
        "outputId": "6470ed69-8da1-4aa5-d9c1-9f662c35a499"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_cs</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>word_freq_receive</th>\n",
              "      <th>word_freq_will</th>\n",
              "      <th>word_freq_people</th>\n",
              "      <th>word_freq_report</th>\n",
              "      <th>word_freq_addresses</th>\n",
              "      <th>word_freq_free</th>\n",
              "      <th>word_freq_business</th>\n",
              "      <th>word_freq_email</th>\n",
              "      <th>word_freq_you</th>\n",
              "      <th>word_freq_credit</th>\n",
              "      <th>word_freq_your</th>\n",
              "      <th>word_freq_font</th>\n",
              "      <th>word_freq_000</th>\n",
              "      <th>word_freq_money</th>\n",
              "      <th>word_freq_hp</th>\n",
              "      <th>word_freq_hpl</th>\n",
              "      <th>word_freq_george</th>\n",
              "      <th>word_freq_650</th>\n",
              "      <th>word_freq_lab</th>\n",
              "      <th>word_freq_labs</th>\n",
              "      <th>word_freq_telnet</th>\n",
              "      <th>word_freq_857</th>\n",
              "      <th>word_freq_data</th>\n",
              "      <th>word_freq_415</th>\n",
              "      <th>word_freq_85</th>\n",
              "      <th>word_freq_technology</th>\n",
              "      <th>word_freq_1999</th>\n",
              "      <th>word_freq_parts</th>\n",
              "      <th>word_freq_pm</th>\n",
              "      <th>word_freq_direct</th>\n",
              "      <th>0.32.2</th>\n",
              "      <th>word_freq_meeting</th>\n",
              "      <th>word_freq_original</th>\n",
              "      <th>word_freq_project</th>\n",
              "      <th>word_freq_re</th>\n",
              "      <th>word_freq_edu</th>\n",
              "      <th>word_freq_table</th>\n",
              "      <th>word_freq_conference</th>\n",
              "      <th>char_freq_colon</th>\n",
              "      <th>char_freq_parenthesis</th>\n",
              "      <th>char_freq_square</th>\n",
              "      <th>char_freq_apost</th>\n",
              "      <th>char_freq_dollar</th>\n",
              "      <th>char_freq_hash</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <th>Spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.223</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>15</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   word_freq_make  word_freq_address  ...  capital_run_length_total  Spam\n",
              "0            0.21               0.28  ...                      1028     1\n",
              "1            0.06               0.00  ...                      2259     1\n",
              "2            0.00               0.00  ...                       191     1\n",
              "3            0.00               0.00  ...                       191     1\n",
              "4            0.00               0.00  ...                        54     1\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Checking the Data**"
      ],
      "metadata": {
        "id": "KU9vgnXupGMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwIcZJG8jSUx",
        "outputId": "bef43af3-656f-435b-dae1-5f9c85f42a2e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4600, 58)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking whether each column has an appropriate datatype\n",
        "#\n",
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urn1l9HCjTcL",
        "outputId": "1f74a1b5-d891-4854-d82d-996da3f4e458"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "word_freq_make                float64\n",
              "word_freq_address             float64\n",
              "word_freq_all                 float64\n",
              "word_freq_3d                  float64\n",
              "word_freq_cs                  float64\n",
              "word_freq_over                float64\n",
              "word_freq_remove              float64\n",
              "word_freq_internet            float64\n",
              "word_freq_order               float64\n",
              "word_freq_mail                float64\n",
              "word_freq_receive             float64\n",
              "word_freq_will                float64\n",
              "word_freq_people              float64\n",
              "word_freq_report              float64\n",
              "word_freq_addresses           float64\n",
              "word_freq_free                float64\n",
              "word_freq_business            float64\n",
              "word_freq_email               float64\n",
              "word_freq_you                 float64\n",
              "word_freq_credit              float64\n",
              "word_freq_your                float64\n",
              "word_freq_font                float64\n",
              "word_freq_000                 float64\n",
              "word_freq_money               float64\n",
              "word_freq_hp                  float64\n",
              "word_freq_hpl                 float64\n",
              "word_freq_george              float64\n",
              "word_freq_650                 float64\n",
              "word_freq_lab                 float64\n",
              "word_freq_labs                float64\n",
              "word_freq_telnet              float64\n",
              "word_freq_857                 float64\n",
              "word_freq_data                float64\n",
              "word_freq_415                 float64\n",
              "word_freq_85                  float64\n",
              "word_freq_technology          float64\n",
              "word_freq_1999                float64\n",
              "word_freq_parts               float64\n",
              "word_freq_pm                  float64\n",
              "word_freq_direct              float64\n",
              "0.32.2                        float64\n",
              "word_freq_meeting             float64\n",
              "word_freq_original            float64\n",
              "word_freq_project             float64\n",
              "word_freq_re                  float64\n",
              "word_freq_edu                 float64\n",
              "word_freq_table               float64\n",
              "word_freq_conference          float64\n",
              "char_freq_colon               float64\n",
              "char_freq_parenthesis         float64\n",
              "char_freq_square              float64\n",
              "char_freq_apost               float64\n",
              "char_freq_dollar              float64\n",
              "char_freq_hash                float64\n",
              "capital_run_length_average    float64\n",
              "capital_run_length_longest      int64\n",
              "capital_run_length_total        int64\n",
              "Spam                            int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. External Data Source Validation**"
      ],
      "metadata": {
        "id": "ISSB47O4php4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By checking other sources having the same dataset we notice that we have what can be considered the best version of the data we can get."
      ],
      "metadata": {
        "id": "DhG3PhzZpjcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Tidying the Dataset**"
      ],
      "metadata": {
        "id": "v9PkMN8gpmZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifying the Missing Data\n",
        "#\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eerxztu6psrs",
        "outputId": "299f07a6-44ae-4e8f-baac-b44d80fee379"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "word_freq_make                0\n",
              "word_freq_address             0\n",
              "word_freq_all                 0\n",
              "word_freq_3d                  0\n",
              "word_freq_cs                  0\n",
              "word_freq_over                0\n",
              "word_freq_remove              0\n",
              "word_freq_internet            0\n",
              "word_freq_order               0\n",
              "word_freq_mail                0\n",
              "word_freq_receive             0\n",
              "word_freq_will                0\n",
              "word_freq_people              0\n",
              "word_freq_report              0\n",
              "word_freq_addresses           0\n",
              "word_freq_free                0\n",
              "word_freq_business            0\n",
              "word_freq_email               0\n",
              "word_freq_you                 0\n",
              "word_freq_credit              0\n",
              "word_freq_your                0\n",
              "word_freq_font                0\n",
              "word_freq_000                 0\n",
              "word_freq_money               0\n",
              "word_freq_hp                  0\n",
              "word_freq_hpl                 0\n",
              "word_freq_george              0\n",
              "word_freq_650                 0\n",
              "word_freq_lab                 0\n",
              "word_freq_labs                0\n",
              "word_freq_telnet              0\n",
              "word_freq_857                 0\n",
              "word_freq_data                0\n",
              "word_freq_415                 0\n",
              "word_freq_85                  0\n",
              "word_freq_technology          0\n",
              "word_freq_1999                0\n",
              "word_freq_parts               0\n",
              "word_freq_pm                  0\n",
              "word_freq_direct              0\n",
              "0.32.2                        0\n",
              "word_freq_meeting             0\n",
              "word_freq_original            0\n",
              "word_freq_project             0\n",
              "word_freq_re                  0\n",
              "word_freq_edu                 0\n",
              "word_freq_table               0\n",
              "word_freq_conference          0\n",
              "char_freq_colon               0\n",
              "char_freq_parenthesis         0\n",
              "char_freq_square              0\n",
              "char_freq_apost               0\n",
              "char_freq_dollar              0\n",
              "char_freq_hash                0\n",
              "capital_run_length_average    0\n",
              "capital_run_length_longest    0\n",
              "capital_run_length_total      0\n",
              "Spam                          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have no null values."
      ],
      "metadata": {
        "id": "qyZV0Bl3pyjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for duplicated values\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Qh4khssp4JA",
        "outputId": "fed44720-7fdc-4067-921e-6b8f38af494c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "391"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Exploratory Analysis**"
      ],
      "metadata": {
        "id": "cT-umJYFYqpG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We notice that this dataset has been presented in  a way that it is diffucult to perform Exploratory Data Analysis, So we are going to do its analysis straight away."
      ],
      "metadata": {
        "id": "9jwvxmcoYtij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Implementing the Solution**"
      ],
      "metadata": {
        "id": "adAN2AlMZGbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We notice that some entries are zero so we smoothe the dataset to avoid zero frequency error."
      ],
      "metadata": {
        "id": "jbsC6YB0KKCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating target columns with feature set\n",
        "X = df.drop(['Spam'], axis=1)\n",
        "y = df['Spam']"
      ],
      "metadata": {
        "id": "hx1qJcjzKXyv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.1. Using 80:20 ratio**"
      ],
      "metadata": {
        "id": "IpdpSYjJUdoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting our data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) "
      ],
      "metadata": {
        "id": "Ww8CSXZ9P4_j"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#since all the column values are continous we are going to use Gaussian Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "clf = GaussianNB()  \n",
        "model = clf.fit(X_train, y_train)\n",
        "y_pred1 = model.predict(X_test)"
      ],
      "metadata": {
        "id": "6JlgUc4XUlDR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the accuracy of our model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred1))\n",
        "print(classification_report(y_test, y_pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9EeMgA1VceX",
        "outputId": "776b7b38-d54c-413b-863c-f767ec359b10"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[392 146]\n",
            " [ 10 372]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.73      0.83       538\n",
            "           1       0.72      0.97      0.83       382\n",
            "\n",
            "    accuracy                           0.83       920\n",
            "   macro avg       0.85      0.85      0.83       920\n",
            "weighted avg       0.87      0.83      0.83       920\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a 80:20 ratio we find a accuracy of 83%. The precision and recall values seem to be varying quite much."
      ],
      "metadata": {
        "id": "Arpq4EJgVudi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.2. Using 70:30 Ratio**"
      ],
      "metadata": {
        "id": "klfiBIyVWB6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting our data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "pzpfCdNNWI79"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#since all the column values are continous we are going to use Gaussian Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "clf = GaussianNB()  \n",
        "model = clf.fit(X_train, y_train)\n",
        "y_pred2 = model.predict(X_test)"
      ],
      "metadata": {
        "id": "NPSuxsdDWXW3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the accuracy of our model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred2))\n",
        "print(classification_report(y_test, y_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMbIY-82WeE5",
        "outputId": "ea382563-e24c-4c8b-c151-027d57acf4bf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[600 222]\n",
            " [ 15 543]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.73      0.84       822\n",
            "           1       0.71      0.97      0.82       558\n",
            "\n",
            "    accuracy                           0.83      1380\n",
            "   macro avg       0.84      0.85      0.83      1380\n",
            "weighted avg       0.87      0.83      0.83      1380\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy score does not change from the previous ratio."
      ],
      "metadata": {
        "id": "U1SNo2t9WoiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.3. Using 60:40 ratio**"
      ],
      "metadata": {
        "id": "suyozS0NWvW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting our data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
      ],
      "metadata": {
        "id": "ADrqHK45W0j_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#since all the column values are continous we are going to use Gaussian Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "clf = GaussianNB()  \n",
        "model = clf.fit(X_train, y_train)\n",
        "y_pred3 = model.predict(X_test)"
      ],
      "metadata": {
        "id": "oyUzyvxDW_X3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the accuracy of our model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred3))\n",
        "print(classification_report(y_test, y_pred3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKoa_ChCXDb2",
        "outputId": "1e833d81-0ad8-48fc-9b80-e8d600604c01"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[791 306]\n",
            " [ 25 718]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.72      0.83      1097\n",
            "           1       0.70      0.97      0.81       743\n",
            "\n",
            "    accuracy                           0.82      1840\n",
            "   macro avg       0.84      0.84      0.82      1840\n",
            "weighted avg       0.86      0.82      0.82      1840\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We note that using a ratio of 60:40 reduces the accuracy slightly to 82%"
      ],
      "metadata": {
        "id": "6kQhj6s9XIxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Conclusion**"
      ],
      "metadata": {
        "id": "sIogJKE6ZbSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We notice that changing the test and train size doesn't much affect the accuracy when working with naive bayes classifier."
      ],
      "metadata": {
        "id": "SAoyMCNKZg-C"
      }
    }
  ]
}